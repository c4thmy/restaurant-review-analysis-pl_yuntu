#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å«©ç‰›å®¶æ½®æ±•ç«é”…æ·±åº¦æ•°æ®åˆ†æå·¥å…·
Deep Analysis Tool for Nenniu Chaoshan Hotpot

ä¸“é—¨é’ˆå¯¹å«©ç‰›å®¶æ½®æ±•ç«é”…å“ç‰Œçš„å…¨é¢æ•°æ®åˆ†æ
"""

import json
import requests
import time
from datetime import datetime
import os
import sys

# è®¾ç½®æ§åˆ¶å°ç¼–ç 
if sys.platform == 'win32':
    import codecs
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.detach())

def load_api_keys():
    """åŠ è½½APIå¯†é’¥"""
    try:
        with open('api_keys_template.json', 'r', encoding='utf-8') as f:
            config = json.load(f)

        api_keys = {}
        for platform, key in config.items():
            if not platform.startswith('_') and key and 'your_' not in str(key):
                api_keys[platform] = key

        return api_keys
    except Exception as e:
        print(f"åŠ è½½APIå¯†é’¥å¤±è´¥: {e}")
        return {}

def search_nenniu_stores(api_key):
    """æœç´¢å«©ç‰›å®¶æ½®æ±•ç«é”…åœ¨åŒ—äº¬çš„æ‰€æœ‰é—¨åº—"""

    print("ğŸ” å¼€å§‹æœç´¢å«©ç‰›å®¶æ½®æ±•ç«é”…åœ¨åŒ—äº¬çš„é—¨åº—...")

    # å¤šä¸ªå…³é”®è¯æœç´¢ç¡®ä¿å…¨è¦†ç›–
    keywords = [
        "å«©ç‰›å®¶",
        "å«©ç‰›å®¶æ½®æ±•ç«é”…",
        "å«©ç‰›å®¶ç«é”…",
        "å«©ç‰›å®¶æ½®æ±•"
    ]

    all_stores = []

    for keyword in keywords:
        print(f"  æ­£åœ¨æœç´¢å…³é”®è¯: {keyword}")

        url = "https://restapi.amap.com/v3/place/text"
        params = {
            'key': api_key,
            'keywords': keyword,
            'city': 'åŒ—äº¬',
            'types': '050000',  # é¤é¥®æœåŠ¡
            'page': 1,
            'offset': 50,
            'output': 'json',
            'extensions': 'all'
        }

        try:
            response = requests.get(url, params=params, timeout=15)
            response.raise_for_status()
            data = response.json()

            if data.get('status') == '1':
                pois = data.get('pois', [])

                for poi in pois:
                    # åªä¿ç•™çœŸæ­£çš„å«©ç‰›å®¶é—¨åº—
                    name = poi.get('name', '')
                    if 'å«©ç‰›å®¶' in name:
                        store = {
                            'id': poi.get('id'),
                            'name': name,
                            'address': poi.get('address', ''),
                            'location': {
                                'lat': float(poi.get('location', '0,0').split(',')[1]) if poi.get('location') else 0,
                                'lng': float(poi.get('location', '0,0').split(',')[0]) if poi.get('location') else 0
                            },
                            'phone': poi.get('tel', ''),
                            'category': poi.get('type', ''),
                            'tags': poi.get('tag', '').split(';') if poi.get('tag') else [],
                            'district': poi.get('adname', ''),
                            'business_area': poi.get('business_area', ''),
                            'search_keyword': keyword,
                            'raw_data': poi
                        }
                        all_stores.append(store)

                print(f"    æ‰¾åˆ° {len(pois)} å®¶ç›¸å…³é¤å…")
            else:
                print(f"    APIè¿”å›é”™è¯¯: {data.get('info', 'æœªçŸ¥é”™è¯¯')}")

            time.sleep(0.5)  # é¿å…è¯·æ±‚è¿‡é¢‘

        except Exception as e:
            print(f"    æœç´¢ {keyword} æ—¶å‡ºé”™: {e}")

    # å»é‡å¤„ç† - åŸºäºé¤å…IDå»é‡
    unique_stores = {}
    for store in all_stores:
        store_id = store['id']
        if store_id not in unique_stores:
            unique_stores[store_id] = store

    final_stores = list(unique_stores.values())
    print(f"âœ… å»é‡åæ€»å…±æ‰¾åˆ° {len(final_stores)} å®¶å«©ç‰›å®¶é—¨åº—")

    return final_stores

def analyze_store_distribution(stores):
    """åˆ†æé—¨åº—åˆ†å¸ƒç­–ç•¥"""

    print("\nğŸ“Š åˆ†æå«©ç‰›å®¶é—¨åº—åˆ†å¸ƒç­–ç•¥...")

    # åŒºåŸŸåˆ†å¸ƒç»Ÿè®¡
    district_stats = {}
    business_area_stats = {}
    location_analysis = []

    for store in stores:
        # åŒºåŸŸç»Ÿè®¡
        district = store.get('district', 'æœªçŸ¥åŒºåŸŸ')
        district_stats[district] = district_stats.get(district, 0) + 1

        # å•†åœˆç»Ÿè®¡
        business_area = store.get('business_area', '')
        if business_area:
            business_area_stats[business_area] = business_area_stats.get(business_area, 0) + 1

        # ä½ç½®è¯¦ç»†åˆ†æ
        location_info = {
            'name': store['name'],
            'district': district,
            'business_area': business_area,
            'address': store['address'],
            'coordinates': store['location']
        }
        location_analysis.append(location_info)

    # é—¨åº—å‘½åæ¨¡å¼åˆ†æ
    naming_patterns = {}
    for store in stores:
        name = store['name']
        # æå–é—¨åº—ä½ç½®æ ‡è¯†
        if '(' in name and ')' in name:
            location_tag = name.split('(')[1].split(')')[0]
            naming_patterns[location_tag] = naming_patterns.get(location_tag, 0) + 1

    distribution_analysis = {
        'total_stores': len(stores),
        'district_distribution': dict(sorted(district_stats.items(), key=lambda x: x[1], reverse=True)),
        'business_area_distribution': dict(sorted(business_area_stats.items(), key=lambda x: x[1], reverse=True)),
        'naming_patterns': dict(sorted(naming_patterns.items(), key=lambda x: x[1], reverse=True)),
        'store_locations': location_analysis,
        'coverage_analysis': {
            'districts_covered': len(district_stats),
            'business_areas_covered': len(business_area_stats),
            'average_stores_per_district': round(len(stores) / len(district_stats), 2) if district_stats else 0
        }
    }

    return distribution_analysis

def competitor_analysis(api_key):
    """ç«å“å¯¹æ¯”åˆ†æ"""

    print("\nğŸ¥Š å¼€å§‹ç«å“å¯¹æ¯”åˆ†æ...")

    # ä¸»è¦ç«é”…å“ç‰Œç«å“
    competitors = [
        "æµ·åº•æç«é”…",
        "å‘·å“ºå‘·å“º",
        "å°é¾™åç«é”…",
        "å·´å¥´æ¯›è‚šç«é”…",
        "æ¹Šæ¹Šç«é”…",
        "å¤§é¾™ç‡šç«é”…",
        "èœ€å¤§ä¾ ç«é”…"
    ]

    competitor_data = {}

    for competitor in competitors:
        print(f"  æ­£åœ¨åˆ†æç«å“: {competitor}")

        url = "https://restapi.amap.com/v3/place/text"
        params = {
            'key': api_key,
            'keywords': competitor,
            'city': 'åŒ—äº¬',
            'types': '050000',
            'page': 1,
            'offset': 1,  # åªéœ€è¦æ•°é‡ï¼Œä¸éœ€è¦è¯¦ç»†ä¿¡æ¯
            'output': 'json',
            'extensions': 'base'
        }

        try:
            response = requests.get(url, params=params, timeout=10)
            data = response.json()

            if data.get('status') == '1':
                count = int(data.get('count', 0))
                competitor_data[competitor] = {
                    'store_count': count,
                    'market_share_estimate': 0  # åç»­è®¡ç®—
                }
                print(f"    {competitor}: {count} å®¶é—¨åº—")
            else:
                print(f"    {competitor}: æŸ¥è¯¢å¤±è´¥")
                competitor_data[competitor] = {'store_count': 0, 'market_share_estimate': 0}

            time.sleep(0.3)

        except Exception as e:
            print(f"    åˆ†æ {competitor} æ—¶å‡ºé”™: {e}")
            competitor_data[competitor] = {'store_count': 0, 'market_share_estimate': 0}

    # è®¡ç®—å¸‚åœºä»½é¢ä¼°ç®—
    total_competitor_stores = sum(data['store_count'] for data in competitor_data.values())

    if total_competitor_stores > 0:
        for competitor, data in competitor_data.items():
            data['market_share_estimate'] = round(data['store_count'] / total_competitor_stores * 100, 1)

    return competitor_data

def generate_business_insights(nenniu_analysis, competitor_data):
    """ç”Ÿæˆå•†ä¸šæ´å¯Ÿ"""

    print("\nğŸ’¡ ç”Ÿæˆå•†ä¸šæ´å¯Ÿ...")

    nenniu_store_count = nenniu_analysis['total_stores']

    # å¸‚åœºåœ°ä½åˆ†æ
    all_brands = dict(competitor_data)
    all_brands['å«©ç‰›å®¶æ½®æ±•ç«é”…'] = {'store_count': nenniu_store_count}

    # æŒ‰é—¨åº—æ•°é‡æ’åº
    brand_ranking = sorted(all_brands.items(), key=lambda x: x[1]['store_count'], reverse=True)

    # æ‰¾åˆ°å«©ç‰›å®¶çš„æ’å
    nenniu_rank = None
    for i, (brand, data) in enumerate(brand_ranking, 1):
        if brand == 'å«©ç‰›å®¶æ½®æ±•ç«é”…':
            nenniu_rank = i
            break

    # é€‰å€ç­–ç•¥åˆ†æ
    district_dist = nenniu_analysis['district_distribution']
    top_districts = list(district_dist.items())[:3]

    # æ‰©å¼ æœºä¼šåˆ†æ
    expansion_opportunities = []

    # å¯»æ‰¾é—¨åº—å¯†åº¦è¾ƒä½ä½†ç«å“è¾ƒå¤šçš„åŒºåŸŸ
    for competitor, data in competitor_data.items():
        if data['store_count'] > nenniu_store_count * 2:  # ç«å“é—¨åº—æ•°é‡æ˜¯å«©ç‰›å®¶çš„2å€ä»¥ä¸Š
            expansion_opportunities.append({
                'opportunity_type': 'underserved_market',
                'description': f'{competitor}åœ¨åŒ—äº¬æœ‰{data["store_count"]}å®¶é—¨åº—ï¼Œæ˜¾ç¤ºè¯¥å¸‚åœºæœ‰è¾ƒå¤§éœ€æ±‚',
                'recommendation': 'è€ƒè™‘åœ¨çƒ­é—¨å•†åœˆå¢åŠ é—¨åº—å¯†åº¦'
            })

    insights = {
        'market_position': {
            'total_stores': nenniu_store_count,
            'market_rank': nenniu_rank,
            'rank_description': f'åœ¨ä¸»è¦ç«é”…å“ç‰Œä¸­æ’åç¬¬{nenniu_rank}ä½' if nenniu_rank else 'æ’åå¾…ç¡®å®š',
            'top_competitor': brand_ranking[0][0] if brand_ranking else None,
            'competitive_gap': brand_ranking[0][1]['store_count'] - nenniu_store_count if brand_ranking else 0
        },
        'location_strategy': {
            'primary_districts': top_districts,
            'coverage_breadth': nenniu_analysis['coverage_analysis']['districts_covered'],
            'strategy_type': 'ç²¾å“åŒ–é€‰å€' if nenniu_store_count < 10 else 'è§„æ¨¡åŒ–æ‰©å¼ ',
            'density_analysis': nenniu_analysis['coverage_analysis']['average_stores_per_district']
        },
        'expansion_opportunities': expansion_opportunities,
        'brand_positioning': {
            'category': 'æ½®æ±•ç«é”…',
            'differentiation': 'ä¸“ä¸šæ½®æ±•ç«é”…ï¼Œä¸ä¼ ç»Ÿå››å·ç«é”…å·®å¼‚åŒ–ç«äº‰',
            'target_market': 'è¿½æ±‚æ­£å®—æ½®æ±•é£å‘³çš„æ¶ˆè´¹è€…'
        }
    }

    return insights

def save_analysis_results(nenniu_stores, distribution_analysis, competitor_data, insights):
    """ä¿å­˜åˆ†æç»“æœ"""

    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

    # å®Œæ•´åˆ†ææŠ¥å‘Š
    comprehensive_report = {
        'report_metadata': {
            'brand': 'å«©ç‰›å®¶æ½®æ±•ç«é”…',
            'analysis_city': 'åŒ—äº¬',
            'analysis_date': datetime.now().isoformat(),
            'data_source': 'é«˜å¾·åœ°å›¾API',
            'report_type': 'å“ç‰Œæ·±åº¦åˆ†ææŠ¥å‘Š'
        },
        'raw_data': {
            'store_details': nenniu_stores,
            'total_stores_found': len(nenniu_stores)
        },
        'distribution_analysis': distribution_analysis,
        'competitor_analysis': competitor_data,
        'business_insights': insights,
        'analysis_summary': {
            'key_findings': [
                f'å«©ç‰›å®¶åœ¨åŒ—äº¬å…±æœ‰{len(nenniu_stores)}å®¶é—¨åº—',
                f'ä¸»è¦åˆ†å¸ƒåœ¨{list(distribution_analysis["district_distribution"].keys())[:3]}',
                f'åœ¨ç«é”…å¸‚åœºæ’åç¬¬{insights["market_position"]["market_rank"]}ä½' if insights["market_position"]["market_rank"] else 'å¸‚åœºåœ°ä½å¾…ç¡®å®š'
            ]
        }
    }

    # ä¿å­˜å®Œæ•´æŠ¥å‘Š
    report_file = f'data/nenniu_comprehensive_analysis_åŒ—äº¬_{timestamp}.json'
    os.makedirs('data', exist_ok=True)

    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(comprehensive_report, f, ensure_ascii=False, indent=2)

    print(f"ğŸ“„ å®Œæ•´åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {report_file}")

    return comprehensive_report, report_file

def display_analysis_summary(report):
    """æ˜¾ç¤ºåˆ†ææ‘˜è¦"""

    print("\n" + "="*70)
    print("ğŸ¯ å«©ç‰›å®¶æ½®æ±•ç«é”…æ·±åº¦åˆ†ææŠ¥å‘Š")
    print("="*70)

    # åŸºæœ¬ä¿¡æ¯
    metadata = report['report_metadata']
    raw_data = report['raw_data']
    distribution = report['distribution_analysis']
    insights = report['business_insights']

    print(f"ğŸ“Š åˆ†ææ¦‚å†µ:")
    print(f"  å“ç‰Œ: {metadata['brand']}")
    print(f"  åŸå¸‚: {metadata['analysis_city']}")
    print(f"  é—¨åº—æ€»æ•°: {raw_data['total_stores_found']} å®¶")
    print(f"  åˆ†ææ—¶é—´: {metadata['analysis_date'][:19]}")

    # é—¨åº—åˆ†å¸ƒ
    print(f"\nğŸ—ºï¸ é—¨åº—åˆ†å¸ƒåˆ†æ:")
    print(f"  è¦†ç›–åŒºåŸŸ: {distribution['coverage_analysis']['districts_covered']} ä¸ªåŒº")
    print(f"  å¹³å‡å¯†åº¦: {distribution['coverage_analysis']['average_stores_per_district']} å®¶/åŒº")

    print(f"\nğŸ“ ä¸»è¦åˆ†å¸ƒåŒºåŸŸ:")
    for district, count in list(distribution['district_distribution'].items())[:5]:
        percentage = round(count / raw_data['total_stores_found'] * 100, 1)
        print(f"  {district}: {count} å®¶ ({percentage}%)")

    if distribution['business_area_distribution']:
        print(f"\nğŸ¢ çƒ­é—¨å•†åœˆ:")
        for area, count in list(distribution['business_area_distribution'].items())[:3]:
            print(f"  {area}: {count} å®¶é—¨åº—")

    # å¸‚åœºåœ°ä½
    market_pos = insights['market_position']
    print(f"\nğŸ† å¸‚åœºåœ°ä½åˆ†æ:")
    print(f"  å¸‚åœºæ’å: {market_pos['rank_description']}")
    if market_pos['top_competitor']:
        print(f"  é¢†å…ˆå“ç‰Œ: {market_pos['top_competitor']}")
        print(f"  é—¨åº—å·®è·: {market_pos['competitive_gap']} å®¶")

    # ç«å“å¯¹æ¯”
    competitor_data = report['competitor_analysis']
    print(f"\nğŸ¥Š ä¸»è¦ç«å“å¯¹æ¯”:")
    sorted_competitors = sorted(competitor_data.items(), key=lambda x: x[1]['store_count'], reverse=True)
    for brand, data in sorted_competitors[:5]:
        print(f"  {brand}: {data['store_count']} å®¶ ({data['market_share_estimate']}%)")

    # é—¨åº—è¯¦æƒ…å±•ç¤º
    print(f"\nğŸª é—¨åº—è¯¦æƒ…æ ·æœ¬:")
    for i, store in enumerate(raw_data['store_details'][:3], 1):
        print(f"  {i}. {store['name']}")
        print(f"     ğŸ“ {store['address']}")
        print(f"     ğŸ“ {store['phone'] if store['phone'] else 'æš‚æ— ç”µè¯'}")
        print(f"     ğŸ¢ {store['district']} {store['business_area']}")
        print()

    # å•†ä¸šæ´å¯Ÿ
    brand_pos = insights['brand_positioning']
    print(f"ğŸ’¡ å…³é”®æ´å¯Ÿ:")
    print(f"  å“ç‰Œå®šä½: {brand_pos['category']} - {brand_pos['differentiation']}")
    print(f"  é€‰å€ç­–ç•¥: {insights['location_strategy']['strategy_type']}")
    print(f"  ç›®æ ‡å¸‚åœº: {brand_pos['target_market']}")

    if insights['expansion_opportunities']:
        print(f"\nğŸš€ æ‰©å¼ å»ºè®®:")
        for opp in insights['expansion_opportunities'][:2]:
            print(f"  â€¢ {opp['description']}")

    return report

def main():
    """ä¸»å‡½æ•°"""

    print("="*70)
    print("ğŸ¯ å«©ç‰›å®¶æ½®æ±•ç«é”…æ·±åº¦æ•°æ®åˆ†æç³»ç»Ÿ")
    print("="*70)
    print("æ­£åœ¨å¯åŠ¨åˆ†æå¼•æ“...")

    # æ£€æŸ¥APIå¯†é’¥
    api_keys = load_api_keys()
    if 'amap' not in api_keys:
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ°æœ‰æ•ˆçš„é«˜å¾·åœ°å›¾APIå¯†é’¥")
        print("è¯·ç¡®ä¿åœ¨ api_keys_template.json ä¸­é…ç½®äº†æ­£ç¡®çš„å¯†é’¥")
        return

    api_key = api_keys['amap']
    print(f"âœ… APIå¯†é’¥åŠ è½½æˆåŠŸ: {api_key[:8]}...{api_key[-4:]}")

    try:
        # ç¬¬1æ­¥: æœç´¢å«©ç‰›å®¶é—¨åº—
        print(f"\n{'='*50}")
        print("ç¬¬1æ­¥: æœç´¢å«©ç‰›å®¶é—¨åº—æ•°æ®")
        print('='*50)
        nenniu_stores = search_nenniu_stores(api_key)

        if not nenniu_stores:
            print("âŒ æœªæ‰¾åˆ°å«©ç‰›å®¶é—¨åº—æ•°æ®ï¼Œåˆ†æç»ˆæ­¢")
            return

        # ç¬¬2æ­¥: åˆ†æé—¨åº—åˆ†å¸ƒ
        print(f"\n{'='*50}")
        print("ç¬¬2æ­¥: åˆ†æé—¨åº—åˆ†å¸ƒç­–ç•¥")
        print('='*50)
        distribution_analysis = analyze_store_distribution(nenniu_stores)

        # ç¬¬3æ­¥: ç«å“åˆ†æ
        print(f"\n{'='*50}")
        print("ç¬¬3æ­¥: ç«å“å¯¹æ¯”åˆ†æ")
        print('='*50)
        competitor_data = competitor_analysis(api_key)

        # ç¬¬4æ­¥: ç”Ÿæˆå•†ä¸šæ´å¯Ÿ
        print(f"\n{'='*50}")
        print("ç¬¬4æ­¥: ç”Ÿæˆå•†ä¸šæ´å¯Ÿ")
        print('='*50)
        insights = generate_business_insights(distribution_analysis, competitor_data)

        # ç¬¬5æ­¥: ä¿å­˜å’Œå±•ç¤ºç»“æœ
        print(f"\n{'='*50}")
        print("ç¬¬5æ­¥: ç”Ÿæˆåˆ†ææŠ¥å‘Š")
        print('='*50)
        report, report_file = save_analysis_results(
            nenniu_stores, distribution_analysis, competitor_data, insights
        )

        # å±•ç¤ºåˆ†æç»“æœ
        display_analysis_summary(report)

        print("\n" + "="*70)
        print("âœ… å«©ç‰›å®¶æ½®æ±•ç«é”…æ·±åº¦åˆ†æå®Œæˆ!")
        print("="*70)
        print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Šæ–‡ä»¶: {report_file}")
        print(f"ğŸ“Š æ•°æ®æ–‡ä»¶å¯ç”¨äºè¿›ä¸€æ­¥åˆ†æ:")
        print(f"   python ccc-main.py analyze {report_file}")
        print("="*70)

    except KeyboardInterrupt:
        print("\n\nâš ï¸ åˆ†æè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ åˆ†æè¿‡ç¨‹å‡ºç°é”™è¯¯: {e}")
        print("è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒAPIå¯†é’¥é…ç½®")

if __name__ == "__main__":
    main()